{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provided datasets\n",
    "\n",
    "`aeon` ships several example data sets for machine learning tasks in the module\n",
    "`datasets`. This notebook gives an overview of what is available by default. For\n",
    "downloading data from other archives, see the [loading data from web notebook](load_data_from_web.ipynb). For further details on the form of the\n",
    "data, see the [data loading notebook](data_loading.ipynb).\n",
    "\n",
    "## Forecasting\n",
    "\n",
    "Forecasting data are stored in csv files with a header for column names. Six standard\n",
    " example datasets are shipped by default:\n",
    "\n",
    "| dataset name | loader function | properties |\n",
    "|----------|:-------------:|------:|\n",
    "| Box/Jenkins airline data | `load_airline` | univariate |\n",
    "| Lynx sales data | `load_lynx` | univariate |\n",
    "| Shampoo sales data | `load_shampoo_sales` | univariate |\n",
    "| Pharmaceutical Benefit Scheme data | `load_PBS_dataset` | univariate |\n",
    "| Longley US macroeconomic data | `load_longley` | multivariate |\n",
    "| MTS consumption/income data | `load_uschange` | multivariate |\n",
    "\n",
    " These are stored in csv format in time, value format, including a header. For\n",
    " forcasting files, each column that is not an index is considered a time series. For\n",
    " example, the airline data has a single time series each row a time, value pair:\n",
    "\n",
    "    Date,Passengers\n",
    "    1949-01,112\n",
    "    1949-02,118\n",
    "\n",
    "Longley has seven time series, each in its own column. Each row is the same time index:\n",
    "\n",
    "    \"Obs\",\"TOTEMP\",\"GNPDEFL\",\"GNP\",\"UNEMP\",\"ARMED\",\"POP\",\"YEAR\"\n",
    "    1,60323,83,234289,2356,1590,107608,1947\n",
    "    2,61122,88.5,259426,2325,1456,108632,1948\n",
    "    3,60171,88.2,258054,3682,1616,109773,1949\n",
    "\n",
    "The problem specific loading functions return the series as either a `pd.Series` if\n",
    "a single series or, if multiple series, a `pd.DataFrame` with each column a series.\n",
    "There are currently six forecasting problems\n",
    "shipped."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Airline\n",
    "\n",
    "The classic Box & Jenkins airline data. Monthly totals of international\n",
    "    airline passengers, 1949 to 1960. This data shows an increasing trend,\n",
    "    non-constant (increasing) variance and periodic, seasonal patterns. The\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import warnings\n",
    "\n",
    "from aeon.datasets import load_airline\n",
    "from aeon.visualisation import plot_series\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "airline = load_airline()\n",
    "plot_series(airline)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Longley\n",
    "This mulitvariate time series dataset contains various US macroeconomic\n",
    "    variables from 1947 to 1962 that are known to be highly collinear. This loader\n",
    "    returns the series to be forecast (default TOTEMP: total employment) and other\n",
    "    variables that may be useful in  the forecast\n",
    "    GNPDEFL - Gross national product deflator\n",
    "    GNP - Gross national product\n",
    "    UNEMP - Number of unemployed\n",
    "    ARMED - Size of armed forces\n",
    "    POP - Population\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from aeon.datasets import load_longley\n",
    "\n",
    "employment, longley = load_longley()\n",
    "plot_series(employment)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lynx\n",
    "\n",
    "The annual numbers of lynx trappings for 1821â€“1934 in Canada. This\n",
    "    time-series records the number of skins of predators (lynx) that were collected\n",
    "    over several years by the Hudson's Bay Company. Returns a pd.Series"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from aeon.datasets import load_lynx\n",
    "\n",
    "lynx = load_lynx()\n",
    "plot_series(lynx)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PBS_dataset\n",
    "\n",
    "The Pharmaceutical Benefits Scheme (PBS) is the Australian government drugs\n",
    "    subsidy scheme. Data comprises of the numbers of scripts sold each month for immune sera\n",
    "    and immunoglobulin products in Australia. The load function returns a pd.Series."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from aeon.datasets import load_PBS_dataset\n",
    "\n",
    "pbs = load_PBS_dataset()\n",
    "plot_series(pbs)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ShampooSales\n",
    "\n",
    "ShampooSales contains a single monthly time series of the number of sales of\n",
    "shampoo over a three year period. The units are a sales count."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from aeon.datasets import load_shampoo_sales\n",
    "\n",
    "shampoo = load_shampoo_sales()\n",
    "print(type(shampoo))\n",
    "plot_series(shampoo)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "### UsChange\n",
    "\n",
    "Load MTS dataset for forecasting Growth rates of personal consumption and income. The\n",
    " data is quarterly for 188 quarters and contains time series for\n",
    " Consumption, Income, Production, Savings and Unemployment. It returns a pd.Series to\n",
    " forecast (by default, the series Consumption) and a pd.DataFrame containing the\n",
    " other series."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from aeon.datasets import load_uschange\n",
    "\n",
    "consumption, others = load_uschange()\n",
    "print(type(consumption))\n",
    "plot_series(consumption)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Solar\n",
    "Example national solar data\n",
    "    for the GB eletricity network extracted from the Sheffield Solar PV_Live API.\n",
    "    Note that these are estimates of the true solar\n",
    "    generation, since the true values are \"behind the meter\" and essentially\n",
    "    unknown. The returned pandas DataSeries is half hourly."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from aeon.datasets import load_solar\n",
    "\n",
    "solar = load_solar()\n",
    "print(type(solar))\n",
    "plot_series(solar)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Time series clustering, classification and regression\n",
    "\n",
    "We ship several datasets from the UCR/TSML archives. The complete archives (including\n",
    " these examples) are available at the [time series classification site](https://timeseriesclassification.com)\n",
    "  and the [UCR classification and clustering site](https://www.cs.ucr.edu/~eamonn/time_series_data_2018/).\n",
    "  All the archive data can be loaded from these websites or directly\n",
    "from the web in code, see [data downloads](load_data_from_web.ipynb). All\n",
    " data is provided with a default train, test split. Problem loaders have an argument\n",
    " `split`. If not set, the function returns the combined train and test data. If\n",
    " `split` is set to `\"test\"` or `\"train\"`, the required split is return. `split` is\n",
    " not case sensitive. They can also be loaded with the functions `load_classification`\n",
    "  and `load_regression`, which also return meta data. See the notebook [data loading](data_loading.ipynb) for details. The data X is stored in a 3D\n",
    "  numpy array of shape `(n_cases, n_channels, n_timepoints)` unless unequal length,\n",
    "  in which case a list of 2D numpy array is returned.\n",
    "\n",
    "| dataset name                | loader function |                                                                                                                                                                 properties |\n",
    "|-----------------------------|:-------------:|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|\n",
    "| Appliance power consumption | `load_acsf1` |                                                                                                                                             univariate, equal length/index |\n",
    "| Arrowhead shape             | `load_arrow_head` |                                                                                                                                             univariate, equal length/index |\n",
    "| Gunpoint motion             | `load_gunpoint` |                                                                                                                                             univariate, equal length/index |\n",
    "| Italy power demand          | `load_italy_power_demand` |                                                                                                                                             univariate, equal length/index |\n",
    "| Japanese vowels             | `load_japanese_vowels` |                 <br/> <br/>                                                                                                               univariate, unequal length/index |\n",
    "| OSUleaf leaf shape          | `load_osuleaf` |                                                                                                                                             univariate, equal length/index |\n",
    "| Basic motions               | `load_basic_motions` |                                                                                                                                           multivariate, equal length/index |\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ACSF1\n",
    "\n",
    "The dataset is compiled from ACS-F1, the first version of the database of appliance\n",
    "consumption signatures. The dataset contains the power consumption of typical appliances. The recordings are characterized by long idle periods and some high bursts of energy consumption when the appliance is active.\n",
    "\n",
    "The classes correspond to 10 categories of home appliances: mobile phones (via chargers), coffee machines, computer stations (including monitor), fridges and freezers, Hi-Fi systems (CD players), lamp (CFL), laptops (via chargers), microwave ovens, printers, and televisions (LCD or LED).\n",
    "\n",
    "The problem is univariate and equal length. It has high frequency osscilation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from aeon.datasets import load_acsf1\n",
    "\n",
    "trainX, trainy = load_acsf1(split=\"train\")\n",
    "testX, testy = load_acsf1(split=\"test\")\n",
    "print(type(trainX))\n",
    "print(trainX.shape)\n",
    "plt.plot(trainX[0][0][:100])\n",
    "plt.title(\n",
    "    f\"First 100 observations of the first train case of the ACFS1 data, class: \"\n",
    "    f\"({trainy[0]})\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ArrowHead\n",
    "The arrowhead data consists of outlines of the images of\n",
    "arrowheads. The shapes of the projectile points are converted into\n",
    "a time series using the angle-based method. The classification of\n",
    "projectile points is is an <a\n",
    "href=\"http://alumni.cs.ucr.edu/~lexiangy/Shapelet/Proj_Point_Review.pdf\">important\n",
    "topic in anthropology</a>. The classes are based on shape\n",
    "distinctions, such as the presence and location of a notch in the\n",
    "arrow. The problem in the repository is a length normalised version\n",
    "of that used in Ye09shapelets. The three classes are called\n",
    "\"Avonlea\" (0), \"Clovis\" (1) and \"Mix\" (2).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from aeon.datasets import load_arrow_head\n",
    "\n",
    "arrowhead, arrow_labels = load_arrow_head()\n",
    "print(arrowhead.shape)\n",
    "plt.title(\n",
    "    f\"First two cases of the ArrowHead, classes: \"\n",
    "    f\"({arrow_labels[0]}, {arrow_labels[1]})\"\n",
    ")\n",
    "\n",
    "plt.plot(arrowhead[0][0])\n",
    "plt.plot(arrowhead[1][0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### BasicMotions\n",
    "\n",
    "The data was generated as part of a student project where four students performed our activities whilst wearing a smart watch.\n",
    "The watch collects 3D accelerometer and a 3D gyroscope It consists of four classes, which are walking, resting, running and\n",
    "badminton. Participants were required to record motion a total of five times, and the data is sampled once every tenth of a second,\n",
    "for a ten second period. The data is multivariate (six channels) equal length."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from aeon.datasets import load_basic_motions\n",
    "\n",
    "motions, motions_labels = load_basic_motions(split=\"train\")\n",
    "plt.title(\n",
    "    f\"First and second dimensions of the first train instance in BasicMotions data, \"\n",
    "    f\"(student {motions_labels[0]})\"\n",
    ")\n",
    "plt.plot(motions[0][0])\n",
    "plt.plot(motions[0][1])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GunPoint\n",
    "\n",
    "This dataset involves one female actor and one male actor making a motion with their\n",
    "hand. The two classes are: Gun-Draw and Point: For Gun-Draw the actors have their\n",
    "hands by their sides. They draw a replicate gun from a hip-mounted holster, point it\n",
    "at a target for approximately one second, then return the gun to the holster, and\n",
    "their hands to their sides. For Point the actors have their gun by their sides. They\n",
    "point with their index fingers to a target for approximately one second, and then\n",
    "return their hands to their sides. For both classes, The data in the archive is the\n",
    "X-axis motion of the actors right hand.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from aeon.datasets import load_gunpoint\n",
    "\n",
    "gun, gun_labels = load_gunpoint(split=\"test\")\n",
    "plt.title(\n",
    "    f\"First three cases of the test set for GunPoint, classes\"\n",
    "    f\"(actor {gun_labels[0]}, {gun_labels[1]}, {gun_labels[2]})\"\n",
    ")\n",
    "plt.plot(gun[0][0])\n",
    "plt.plot(gun[1][0])\n",
    "plt.plot(gun[2][0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ItalyPowerDemand\n",
    "The data was derived from twelve monthly electrical power demand time series from\n",
    "Italy and first used in the paper \"Intelligent Icons: Integrating Lite-Weight Data\n",
    "Mining and Visualization into GUI Operating Systems\". The classification task is to\n",
    "distinguish days from Oct to March (inclusive) (class 0) from April to September\n",
    "(class 1). The problem is univariate, equal length.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from aeon.datasets import load_italy_power_demand\n",
    "\n",
    "italy, italy_labels = load_italy_power_demand(split=\"train\")\n",
    "plt.title(\n",
    "    f\"First three cases of the test set for ItalyPowerDemand, classes\"\n",
    "    f\"( {italy_labels[0]}, {italy_labels[1]}, {italy_labels[2]})\"\n",
    ")\n",
    "plt.plot(italy[0][0])\n",
    "plt.plot(italy[1][0])\n",
    "plt.plot(italy[2][0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### JapaneseVowels\n",
    "\n",
    "A UCI Archive dataset. See this link for more [detailed information](https://archive.ics.uci.edu/ml/datasets/Japanese+Vowels)\n",
    "\n",
    "Paper: M. Kudo, J. Toyama and M. Shimbo. (1999). \"Multidimensional Curve Classification Using Passing-Through Regions\". Pattern Recognition Letters, Vol. 20, No. 11--13, pages 1103--1111.\n",
    "\n",
    "9 Japanese-male speakers were recorded saying the vowels 'a' and 'e'. A '12-degree linear prediction analysis' is applied to the raw recordings to obtain time-series with 12 dimensions and series lengths between 7 and 29. The classification task is to predict the speaker. Therefore, each instance is a transformed utterance, 12*29 values with a single class label attached, [1...9].\n",
    "\n",
    "The given training set is comprised of 30 utterances for each speaker, however the\n",
    "test set has a varied distribution based on external factors of timing and\n",
    "experimental availability, between 24 and 88 instances per speaker. The data is\n",
    "unequal length"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from aeon.datasets import load_japanese_vowels\n",
    "\n",
    "japan, japan_labels = load_japanese_vowels(split=\"train\")\n",
    "plt.title(\n",
    "    f\"First channel of three test cases for JapaneseVowels, classes\"\n",
    "    f\"({japan_labels[0]}, {japan_labels[10]}, {japan_labels[200]})\"\n",
    ")\n",
    "print(f\" number of cases = \" f\"{len(japan)}\")\n",
    "print(f\" First case shape = \" f\"{japan[0].shape}\")\n",
    "print(f\" Tenth case shape = \" f\"{japan[10].shape}\")\n",
    "print(f\" 200th case shape = \" f\"{japan[200].shape}\")\n",
    "\n",
    "plt.plot(japan[0][0])\n",
    "plt.plot(japan[10][0])\n",
    "plt.plot(japan[200][0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### OSUleaf\n",
    "\n",
    "The OSULeaf data set consist of one dimensional outlines of leaves. The series were\n",
    "obtained by color image segmentation and boundary extraction (in the anti-clockwise\n",
    "direction) from digitized leaf images of six classes: Acer Circinatum, Acer Glabrum,\n",
    "Acer Macrophyllum, Acer Negundo, Quercus Garryana and Quercus Kelloggii for the MSc\n",
    "thesis \"Content-Based Image Retrieval: Plant Species Identification\" by A. Grandhi.\n",
    "OSULeaf is equal length and univariate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from aeon.datasets import load_osuleaf\n",
    "\n",
    "leaf, leaf_labels = load_osuleaf(split=\"train\")\n",
    "plt.title(\n",
    "    f\"First three cases of the test set for OSULeaf, classes\"\n",
    "    f\" ({leaf_labels[0]}, {leaf_labels[1]}, {leaf_labels[2]})\"\n",
    ")\n",
    "plt.plot(leaf[0][0])\n",
    "plt.plot(leaf[1][0])\n",
    "plt.plot(leaf[2][0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PLAID\n",
    "PLAID stands for the Plug Load Appliance Identification Dataset. The data are  intended for load identification research. The first version of PLAID is named PLAID1, collected in summer 2013. A second version of PLAID was collected in winter 2014 and released under the name PLAID2.\n",
    "This dataset comes from PLAID1. It includes current and voltage measurements sampled at 30 kHz from 11 different appliance types present in more than 56 households in Pittsburgh, Pennsylvania, USA. Data collection took place during the summer of 2013. Each appliance type is represented by dozens of different instances of varying makes/models.\n",
    "For each appliance, three to six measurements were collected for each state transition. These measurements were then post-processed to extract a few-second-long window containing both the steady-state operation and the startup transient )when available).\n",
    "The classes correspond to 11 different appliance types: air\n",
    "conditioner (class 0), compact flourescent lamp, fan, fridge,\n",
    "hairdryer , heater, incandescent light bulb, laptop, microwave,\n",
    "vacuum,washing machine (class 10). The data is univariate and unequal length."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from aeon.datasets import load_plaid\n",
    "\n",
    "plaid, plaid_labels = load_plaid(split=\"train\")\n",
    "plt.title(\n",
    "    f\"three train cases for PLAID, classes\"\n",
    "    f\"( {plaid_labels[0]}, {plaid_labels[10]}, {plaid_labels[200]})\"\n",
    ")\n",
    "print(f\" number of cases = \" f\"{len(plaid)}\")\n",
    "print(f\" First case shape = \" f\"{plaid[0].shape}\")\n",
    "print(f\" Tenth case shape = \" f\"{plaid[10].shape}\")\n",
    "print(f\" 200th case shape = \" f\"{plaid[200].shape}\")\n",
    "\n",
    "plt.plot(plaid[0][0])\n",
    "plt.plot(plaid[10][0])\n",
    "plt.plot(plaid[200][0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regression\n",
    "\n",
    "We ship one regression problem from the [Time Series Extrinsic Regression]\n",
    "(http://tseregression.org/) website and one soon to be added."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Covid3Month\n",
    "\n",
    "The goal of this dataset is to predict COVID-19's death rate on 1st April 2020 for each country using daily confirmed cases for the last three months.\n",
    "This dataset contains 201 time series, where each time series is the daily confirmed cases for a country.\n",
    "The data was obtained from WHO's COVID-19 database.\n",
    "Please refer to https://covid19.who.int/ for more details"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from aeon.datasets import load_covid_3month\n",
    "\n",
    "covid, covid_target = load_covid_3month()\n",
    "print(covid.shape)\n",
    "plt.title(\"Response variable for Covid3Months data\")\n",
    "plt.plot(covid_target)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CardanoSentiment\n",
    "\n",
    "By combining historical sentiment data for Cardano cryptocurrency, extracted from\n",
    "    EODHistoricalData and made available on Kaggle, with historical price data for the\n",
    "    same cryptocurrency, extracted from CryptoDataDownload, we created the\n",
    "    CardanoSentiment dataset, with 107 instances. The predictors are hourly close price\n",
    "    (in USD) and traded volume during a day, resulting in 2-dimensional time series of\n",
    "    length 24. The response variable is the normalized sentiment score on the day\n",
    "    spanned by the timepoints."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from aeon.datasets import load_cardano_sentiment\n",
    "\n",
    "cardano, cardano_target = load_cardano_sentiment()\n",
    "print(cardano.shape)\n",
    "plt.title(\"Response variable for cardano data\")\n",
    "plt.plot(cardano_target)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Segmentation\n",
    "\n",
    "Two of the UCR classification data have been adapted for segmentation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ElectricDevices\n",
    "\n",
    "The UCR ElectricDevices dataset series are grouped by class label and concatenated to create\n",
    " segments with repeating temporal patterns and characteristics. The location at which\n",
    "  different classes were concatenated are marked as change points.\n",
    "\n",
    "this function returns a single series,  the period length as an integer and  the\n",
    "change points as a numpy array."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "from aeon.datasets import load_electric_devices_segmentation\n",
    "\n",
    "data, period, change_points = load_electric_devices_segmentation()\n",
    "print(\" Period = \", period)\n",
    "print(\" Change points = \", change_points)\n",
    "plot_series(data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GunPoint Segmentation\n",
    "\n",
    "The UCR GunPoint dataset series are grouped by class label and concatenated to create\n",
    " segments with repeating temporal patterns and characteristics. The location at which\n",
    "  different classes were concatenated are marked as change points.\n",
    "\n",
    "this function returns a single series,  the period length as an integer and  the\n",
    "change points as a numpy array."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "from aeon.datasets import load_gun_point_segmentation\n",
    "\n",
    "data, period, change_points = load_gun_point_segmentation()\n",
    "print(\" Period = \", period)\n",
    "print(\" Change points = \", change_points)\n",
    "plot_series(data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
